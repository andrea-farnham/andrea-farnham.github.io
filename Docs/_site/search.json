[
  {
    "objectID": "contents/presentations/Presentations_1.html",
    "href": "contents/presentations/Presentations_1.html",
    "title": "An overview of the AFFORD project",
    "section": "",
    "text": "An overview of the AFFORD project\nPresented on 17-11-2023 at our CRS retreat (Greuterhof, Islikon), on 24-11-2023 at an online meeting of the Data Stewards Network (UZH) and on 04-04-2024 at the EBPI, UZH lunch seminar\n\n\n&lt;&lt; Back\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/tutorials/index.html",
    "href": "contents/tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Tutorials\nA series of practical tutorials for managing Open Research Data and adhere as much as possible to the FAIR principles. Our tutorials provide guidelines, step-by-step instructions, examples and code to facilitate the following components of data curation.\nExplore All Tutorials\nThe dendrogram below shows a content summary. Use the left side bar to go to the different tutorials or scroll down and use the table below.\n\n\n\n\n\n\n\n\n   \n     \n     Order By\nDefault\n\n          Date - Oldest\n        \n\n          Date - Newest\n        \n\n          Title\n        \n\n    \n      \n      \n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\nDocumentations: Filenames and organization\n\n\nTips and examples for documenting file and folder naming convention \n\n\nMar 13, 2024\n\n\n\n\nGitlab Tutorial 1. Step-by-Step Guide to Git and Gitlab\n\n\nUsing a UZH Gitlab repository for project owners and collaborators\n\n\nFeb 13, 2024\n\n\n\n\nGitlab Tutorial 2. Create and Update a Data Index\n\n\nA workflow to use Gitlab pages as an open data Index\n\n\nMar 13, 2024\n\n\n\n\nGitlab Tutorial 3. Continuous Integration (CI)\n\n\nAdditional details on basic customization of CI pipelines\n\n\nJan 3, 2024\n\n\n\n\nGitlab workflows\n\n\nShowcasing different scenarios\n\n\nMar 13, 2024\n\n\n\n\nMetadata: making JSON files\n\n\nIn this use case we read the JSON fields from a table and create JSON files with generic and file-specific information\n\n\nMar 13, 2024\n\n\n\n\nMetadata: tables\n\n\nGeneral tips on making better human and machine-readable tabular metadata\n\n\nMar 20, 2024\n\n\n\n\nWebsite Tutorial using R, Quarto and Gitlab Pages\n\n\nShare data, code and dynamic reports in an easy-to-build website\n\n\nNov 30, 2023\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorials"
    ]
  },
  {
    "objectID": "contents/tutorials/Tutorial_Metadata_tables.html",
    "href": "contents/tutorials/Tutorial_Metadata_tables.html",
    "title": "Metadata: tables",
    "section": "",
    "text": "Tables are a form of structured metadata with essential information to interpret the data. A common scenario in research is to have a table describing records, cases or subjects, with one row per record and columns describing different features. Then, there are often multiple larger tables with data associated with each record or subject (e.g., physiological measurements, images, test results, etc). These tables may content entries that are automatically generated and others that have to be manually entered by researchers. The tables can be in different formats, although .csv or .tsv are recommended for the sake of interoperability. Spreadsheet software formats like Microsoft Excel or Google Sheets are powerful and widely used by many researchers, as they have more human-friendly features.\n\nPublication review: six tips for better spreadsheets\nWe distill here the main points of the highly recommendable two-pager from the technology editor at Nature (Perkel 2022):\n\n1. Keep raw data raw\nRecommendation: make the original spreadsheet a read-only document and work on copies. Beware of the dangers of autoformatting functions of your spreadsheet software, and on how easy it is to loose track of the user-friendly manipulations done to the file.\n\n\n2. Make data machine-readable\nDo not encode any information with formatting (e.g., in color-coding schemes), create additional columns that can be used as filter if necessary. Formatting can be easily lost during routine table maintenance. Researchers may also struggle to remember what the formatting represents. When read from a machine, the information encoded by formatting may be lost.\n\n\n3. Be consistent\nData-analysis tools expect one specific format: one row of column titles. No merged cells and one table per page. Ideally all cells are filled (blank cells may contain hidden characters) and contain one piece of data (e.g.¬†a cell with ‚Äò3 red beetles‚Äô, better use two columns: one for count and one for insect type). Do not use to subdivided a table into different groups.\n\n\n4. Document your work\nCreate a sheet (or tab) with a codebook that documents abbreviations, units of measurement, missing values, etc.\n\n\n5. Cross-check your data\nIf possible, protect parts of the spreadsheet to prevent undesired manipulations, apply data validation checks to prevent data entry errors. Finally, double-check your work and analysis workflow.\n\n\n6. Think ahead\nPlan ahead what data formats and transformations you may need, and what variables and covariates you may use. Consulting your collaborators will increase the chances of having a table that useful to other researchers.\n\n\n\nTable operations\nResearchers have to manipulate tabular metadata and this is better done by code so that any operation on the raw data can be reproduced. Visit our Templates section for some code snippets and templates showing frequent use cases of these operations.\n\n\n\n\n\n\n\n\n Back to topReferences\n\nPerkel, Jeffrey M. 2022. ‚ÄúSix Tips for Better Spreadsheets.‚Äù Nature 608 (7921): 229‚Äì30. https://doi.org/10.1038/d41586-022-02076-1.",
    "crumbs": [
      "Tutorials",
      "üè∑**Documentation & Metadata**",
      "Metadata: tables"
    ]
  },
  {
    "objectID": "contents/tutorials/Tutorial_Metadata_JSON.html",
    "href": "contents/tutorials/Tutorial_Metadata_JSON.html",
    "title": "Metadata: making JSON files",
    "section": "",
    "text": "Create a JSON file with metadata from tables and data files\nIn this example we create simple human and machine-readable metadata files in JavaScript Object Notation (JSON). They consists of fields of key-value pairs. These are sidecar metadata files, that is, they accompany a separate source data file (for this example we use dummy images as data files). In this use case, researchers can edit a table specifying the fields in the JSON file. This script creates a JSON with these fields. Some of the values in the JSON fields are filled for each of the data files based on the filename and an additional table with metadata (subject information).\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThere are good editors with a graphical interface available online to read and write JSON. We recommend the following website: https://jsoneditoronline.org/\nIn general, we recommend creating JSON files with a script and not manually, to prevent data entry errors. JSON metadata files are part of essential machine-readable metadata, and additional to structured metadata (tables) which may contain human-only readable columns (e.g., ‚Äòcomment‚Äô variables wtih free text notes). JSON files can have more details than the metadata tables.\n\n\n\n\nThis use case is based on:\ninputs\n\nA csv table specifying the JSON keys (e.g., ‚ÄúSynchrotronName‚Äù,‚ÄúSpeciesName‚Äù ) and their values (e.g., ‚Äúmouse‚Äù) when they apply to all files. If a value is blank it will be filled by information in the filename or table with subject information (see below)\nA collection of data files encoding subject ID in their name.\nAn Excel table with subjects information (e.g.,sex, body weight) that has to be added to the JSON file\n\nWe will use the R package jsonlite to write the JSON string\noutputs\nA JSON file per data file with the fields from the table is created for each file with the same filename and the subject ID added in the corresponding json field. In this case the data files are images from mice.\n\n\n\n\n\n\nNote on this example\n\n\n\n\n\nThis demo uses a dummy data set, i.e., the JSON fields and metadata have no real-life meaning.Metadata tables can be prepared in a spreadsheet and saved in different file formats for example csv and Excel. In actual projects the csv file format is preferred over Excel, for the sake of interoperability.\n\n\n\n\n\nHow-to\nCode\n\n\n\nRead table with JSON fields and table with subjects information\n\nCodelibrary(knitr)\nlibrary(dplyr)\nlibrary(kableExtra)\n\n# Enter input directories \ndirinput &lt;- 'dummy_data'\ndiroutput &lt;- '../../_data/'\n\n# Read table with JSON fields \njsonFields &lt;- read.csv(file.path(dirinput,'Dummy_JSON_fields.csv'))\n\n# Read table with subject information\nsubj_info &lt;- openxlsx::read.xlsx(file.path(dirinput,'DummyData1_20241234_subjects.xlsx'), sheet = 'subject_info')\n\n\nRead data filenames and separate subject ID\nHere we read some .jpg pictures with dummy images. The first filename part contains the subject ID.\n\nCode# Create table filenames \nfiles &lt;- dir(file.path(dirinput,'Images')) # Find all files in our images folder\n\n# Use pattern to take only subject images\nfname &lt;- files[grepl(paste0('^DS.*.jpg$'),files)] \ntbl_files &lt;- as.data.frame(fname) \n\n# First filename part contains subject ID. Create new column with that info. \ntbl_files$subject &lt;- sapply(strsplit(fname,'_'),'[[',1) \n\n\nCheck input tables\n\n\nJSON fields\nSubject information\nFilenames\n\n\n\nIn this table we created the column Data.name that indicates the key and the column Permissible.values which will indicate the value in the JSON file. The other columns are not necessary for this example, but can help the users when specifying the content of their JSON files. The entries in Permissible.values will be filled with file-specific information.\n\n\n\n\n\n\nImportant\n\n\n\nThe names of these columns are arbitrary and you can define any other name. It is important to note the format of the values (e.g., numeric, alphanumeric or strings). The values can also be arrays [1,2,3]. A JSON file can have a more hierarchical structure with keys and subkeys. In this example we use a simple structure.\n\n\n\nCode# check \nknitr::kable(jsonFields) %&gt;%\n  scroll_box(height= \"300px\")\n\n\n\n\nJSON_section\nData.name\nData.Description\nData.type\nPermissible.values\n\n\n\nInfo\nSynchrotronName\nName of the synchrotron facility\nstring\nDummy-synchrotron\n\n\nInfo\nSynchrotronAcronym\nAcronym of the synchrotron facility\nstring\nSync1234\n\n\nInfo\nIntendedFor\nName of the source file this metadata describes\nstring\n\n\n\nInfo\nBeamlineAcronym\nInstitution defined name of the machine. Corresponds to DICOM Tag DICOM tag 0008,1010.\nstring\nBL20B2\n\n\nInfo\nBeamtimeSessionStartDate\nYYYY-MM-DD\ndate\n2024-01-13\n\n\nInfo\nBeamtimeSessionEndDate\nYYYY-MM-DD\ndate\n2024-01-13\n\n\nInfo\nSpeciesName\n\nstring\nmouse (mus musculus)\n\n\nInfo\nSpeciesStrain\n\nalphanumeric\nC123456\n\n\nInfo\nSubjectID\n\nalphanumeric\n\n\n\nInfo\nSex\n\nalphanumeric\n\n\n\nInfo\nBodyWeight_gr\n\nnumber\n\n\n\nInfo\nBodyPart\nName of the organ / body region scanned. Corresponds to DICOM Tag DICOM tag 0018,0015.\nstring\nbrain\n\n\nAcquisition\nDetectorArrayWidth\n\nnumber\n123\n\n\nAcquisition\nDetectorArrayHeight\n\nnumber\n456\n\n\nAcquisition\nDetectorBitDepth\n\nnumber\n16\n\n\nAcquisition\nDetectorPixelSize\nin ¬µm\nnumber\n6\n\n\nAcquisition\nRotationAngle\n\nnumber\n180\n\n\nReconstruction\nCenterOfRotationMethod\n\nstring\nmanual\n\n\nReconstruction\nCenterOfRotationValue\nIn pixels\"\nnumber\n3\n\n\nReconstruction\nReconMatrixSize¬†\nSize of the reconstruction matrix¬†in pixels\narray of three numbers\n[1,1,2]\n\n\nReconstruction\nReconMethodNameMethodName\nReconstruction method or algorithm. Corresponds to DICOM Tag 0054,1103.¬†\nstring\ndummy-method\n\n\nReconstruction\nMethodImplementationVersion¬†\nIdentification for the software used, such as name and version (optional)¬†\nstring\nin-house-bash-script-v02\n\n\nReconstruction\nFilterType¬†\nType of post-recon smoothing¬†\nstring\ngaussian\n\n\n\n\n\n\n\n\n\n\nCode# check \nknitr::kable(subj_info) %&gt;%\n  scroll_box(height= \"300px\")\n\n\n\n\nsubjID\nSex\nBody.weight.(g)\nlength.(mm)\nDilut.(x)\nCon.(mg.Ba/ml)\nInt.1.rate.(uL/min)\nInt.2.vol.(uL)\ntime.(HH:MM)\n\n\n\nDS01\nF\n27.50\n2.3\n1.50\n123\n0.25\n5.0\n0.8666667\n\n\nDS02\nF\n26.60\n2.3\n1.50\n123\n0.50\n2.5\n0.4680556\n\n\nDS03\nF\n27.50\n2.3\n1.50\n123\n0.10\n2.5\n0.4173611\n\n\nDS04\nF\n20.20\n2.3\n1.50\n123\n0.50\n5.0\n0.9777778\n\n\nDS05\nM\n20.20\n2.2\n1.50\n123\n0.50\n2.5\n0.7993056\n\n\nDS06\nF\n20.30\n2.2\n1.50\n123\n0.50\n5.0\n0.7006944\n\n\nDS07\nF\n26.40\n2.3\n1.50\n123\n0.10\n2.5\n0.6284722\n\n\nDS08\nF\n24.60\n2.3\n1.50\n123\n0.25\n5.0\nNA\n\n\nDS09\nF\n26.80\n2.3\n1.50\n123\n0.25\n5.0\n0.8402778\n\n\nDS10\nM\n25.70\n2.3\n1.50\n123\n0.50\n2.5\n0.7069444\n\n\nDS11\nF\n24.40\n2.3\n1.50\n123\n0.50\n5.0\n0.6895833\n\n\nDS12\nF\n25.30\n2.3\n1.00\n111\n0.50\n2.5\n0.5312500\n\n\nDS13\nM\n24.70\n2.2\n1.00\n111\n0.10\n2.5\n0.7083333\n\n\nDS14\nM\n27.00\n2.2\n1.00\n111\n0.10\n2.5\n0.9569444\n\n\nDS15\nM\n24.00\n2.2\n1.00\n111\n0.25\n5.0\n0.8638889\n\n\nDS16\nF\n25.80\n2.2\n1.00\n111\n0.25\n5.0\n0.4118056\n\n\nDS17\nM\n26.40\n2.2\n1.00\n111\n0.25\n5.0\nNA\n\n\nDS18\nF\n26.60\n2.2\n0.75\n321\n0.25\n5.0\n0.5805556\n\n\nDS19\nM\n26.90\n2.2\n0.75\n321\n0.50\n5.0\n0.4722222\n\n\nDS20\nM\n26.20\n2.2\n0.75\n321\n0.25\n5.0\n0.6520833\n\n\nDS21\nM\n21.00\n2.2\n0.75\n321\n0.50\n5.0\n0.5486111\n\n\nDS22\nF\n19.50\n2.2\n0.75\n321\n0.10\n2.5\n0.7812500\n\n\nDS23\nF\n19.60\n2.2\n0.75\n321\n0.10\n2.5\n0.7611111\n\n\nDS24\nF\n19.56\n2.3\n0.75\n321\n0.50\n2.5\n0.8715278\n\n\nDS25\nM\n19.63\n2.3\n0.75\n321\n0.25\n5.0\n0.6125000\n\n\nDS26\nM\n19.71\n2.3\n0.75\n321\n0.50\n2.5\n0.5375000\n\n\nDS27\nM\n19.20\n2.2\n0.75\n321\n0.25\n5.0\n0.9298611\n\n\nDS28\nM\n20.20\n2.2\n0.75\n321\n0.50\n2.5\n0.7451389\n\n\nDS29\nM\n18.60\n2.2\n0.75\n321\n0.10\n2.5\n0.4687500\n\n\nDS30\nM\n19.03\n2.2\n0.75\n321\n0.25\n5.0\n0.6833333\n\n\nDS31\nF\n20.50\n2.2\n0.75\n321\n0.25\n5.0\n13.3800000\n\n\nDS32\nF\n20.20\n2.2\n0.75\n321\n0.10\n2.5\n0.6256944\n\n\nDS33\nM\n21.20\n2.2\n0.75\n321\n0.25\n5.0\n0.8361111\n\n\nDS34\nM\n19.21\n2.2\n0.75\n321\n0.10\n2.5\n0.7090278\n\n\n\n\n\n\n\n\n\n\nCode# check \nknitr::kable(tbl_files) %&gt;%\n  scroll_box(height= \"300px\")\n\n\n\n\nfname\nsubject\n\n\n\nDS01_statB_1scan_slc1234.jpg\nDS01\n\n\nDS02_statB_1scan-v3_slc1234.jpg\nDS02\n\n\nDS03_statB_1scan_slc1234.jpg\nDS03\n\n\nDS04_statB_1scan_v2_slc1234.jpg\nDS04\n\n\nDS04_statB_1scan_v3_slc1234.jpg\nDS04\n\n\nDS05_statB_1scan_slc1234.jpg\nDS05\n\n\nDS06_statB_1scan_slc1234.jpg\nDS06\n\n\nDS07_statB_1scan_slc1234.jpg\nDS07\n\n\nDS08_statB_1scan_slc1234.jpg\nDS08\n\n\nDS09_statA_1scan-head_slc1234.jpg\nDS09\n\n\nDS09_statA_1scan-neck_slc1234.jpg\nDS09\n\n\nDS09_statA_1scan-nose-v2_slc1234.jpg\nDS09\n\n\nDS09_statA_1scan-nose_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_001_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_002_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_003_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_004_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_005_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_006_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_007_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_008_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_009_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_010_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_011_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_012_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_013_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_014_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_015_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_016_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_017_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_018_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_019_slc1234.jpg\nDS09\n\n\nDS09_statA_20scan-ph1-Int_020_slc1234.jpg\nDS09\n\n\n\n\n\n\n\n\n\n\nCreate the JSON files\nPrepare table\nPrepare the human-readable table specifying the JSON fields into a suitable format to read with jsonlite::toJSON()\n\nCode# Preserve the sorting of the field names as in the table\nsorted_fieldnames &lt;- factor(jsonFields$Data.name, levels = jsonFields$Data.name) \n\n# Transform table into a list. Each element is a fieldname with its values\njson_data &lt;- lapply(split(jsonFields$Permissible.values,sorted_fieldnames),as.character)\n\n\nAdd file-specific information\nLoop through the image files and fill the file-specific values in the JSON file with information from the table with subject info.\n\nCodelibrary(jsonlite)\n\n# Join tables with filenames and subject information by subjID\nmetadat &lt;- dplyr::full_join(x=tbl_files, y=subj_info, by=join_by('subject'=='subjID'),keep=FALSE)  \n\n# write JSON files \nsaveoutput &lt;- 0\nfor (i in 1:nrow(tbl_files)) {\n  \n  # Complete Fields with info From table \n  json_data$IntendedFor = metadat$fname[i]\n  json_data$SubjectID = metadat$subject[i]\n  json_data$Sex = metadat$Sex[i]\n  json_data$BodyWeight_gr = metadat$`Body.weight.(g)`[i]\n  \n  \n  # Convert the list to a JSON string\n  json_string &lt;- toJSON(json_data, pretty = TRUE, auto_unbox = TRUE)\n  \n  # Save the JSON string to a file\n  if (saveoutput == 1) {\n    ouputfilename &lt;- gsub('.jpg','.json',tbl_files$fname[i]) # rename input file\n    write(json_string, file.path(diroutput, ouputfilename))  \n    print(paste0(\"Wrote \", file.path(diroutput, ouputfilename)))\n  }\n  \n  # clean json \n  rm (json_string)\n}\n\n\nOutput Examples\nThe r package jsonlite offers several formatting options. Depending on your needs you may have some preferences.\n\n\nJSON with auto_unbox = TRUE\nJSON with auto_unbox = FALSE\n\n\n\n\nCodeprint(toJSON(json_data, pretty = TRUE, auto_unbox = TRUE))\n\n{\n  \"SynchrotronName\": \"Dummy-synchrotron\",\n  \"SynchrotronAcronym\": \"Sync1234\",\n  \"IntendedFor\": \"DS09_statA_20scan-ph1-Int_020_slc1234.jpg\",\n  \"BeamlineAcronym\": \"BL20B2\",\n  \"BeamtimeSessionStartDate\": \"2024-01-13\",\n  \"BeamtimeSessionEndDate\": \"2024-01-13\",\n  \"SpeciesName\": \"mouse (mus musculus)\",\n  \"SpeciesStrain\": \"C123456 \",\n  \"SubjectID\": \"DS09\",\n  \"Sex\": \"F\",\n  \"BodyWeight_gr\": 26.8,\n  \"BodyPart\": \"brain\",\n  \"DetectorArrayWidth\": \"123\",\n  \"DetectorArrayHeight\": \"456\",\n  \"DetectorBitDepth\": \"16\",\n  \"DetectorPixelSize\": \"6\",\n  \"RotationAngle\": \"180\",\n  \"CenterOfRotationMethod\": \"manual\",\n  \"CenterOfRotationValue\": \"3\",\n  \"ReconMatrixSize¬†\": \"[1,1,2]\",\n  \"ReconMethodNameMethodName\": \"dummy-method\",\n  \"MethodImplementationVersion¬†\": \"in-house-bash-script-v02\",\n  \"FilterType¬†\": \"gaussian\"\n} \n\n\n\n\n\nCodeprint(toJSON(json_data, pretty = TRUE, auto_unbox = FALSE))\n\n{\n  \"SynchrotronName\": [\"Dummy-synchrotron\"],\n  \"SynchrotronAcronym\": [\"Sync1234\"],\n  \"IntendedFor\": [\"DS09_statA_20scan-ph1-Int_020_slc1234.jpg\"],\n  \"BeamlineAcronym\": [\"BL20B2\"],\n  \"BeamtimeSessionStartDate\": [\"2024-01-13\"],\n  \"BeamtimeSessionEndDate\": [\"2024-01-13\"],\n  \"SpeciesName\": [\"mouse (mus musculus)\"],\n  \"SpeciesStrain\": [\"C123456 \"],\n  \"SubjectID\": [\"DS09\"],\n  \"Sex\": [\"F\"],\n  \"BodyWeight_gr\": [26.8],\n  \"BodyPart\": [\"brain\"],\n  \"DetectorArrayWidth\": [\"123\"],\n  \"DetectorArrayHeight\": [\"456\"],\n  \"DetectorBitDepth\": [\"16\"],\n  \"DetectorPixelSize\": [\"6\"],\n  \"RotationAngle\": [\"180\"],\n  \"CenterOfRotationMethod\": [\"manual\"],\n  \"CenterOfRotationValue\": [\"3\"],\n  \"ReconMatrixSize¬†\": [\"[1,1,2]\"],\n  \"ReconMethodNameMethodName\": [\"dummy-method\"],\n  \"MethodImplementationVersion¬†\": [\"in-house-bash-script-v02\"],\n  \"FilterType¬†\": [\"gaussian\"]\n} \n\n\n\n\n\n\n\n\n\nCodelibrary(knitr)\nlibrary(dplyr)\nlibrary(kableExtra)\n\n# Enter input directories \ndirinput &lt;- 'dummy_data'\ndiroutput &lt;- '../../_data/'\n\n# Read table with JSON fields \njsonFields &lt;- read.csv(file.path(dirinput,'Dummy_JSON_fields.csv'))\n\n# Read table with subject information\nsubj_info &lt;- openxlsx::read.xlsx(file.path(dirinput,'DummyData1_20241234_subjects.xlsx'), sheet = 'subject_info')\n\n# Create table filenames \nfiles &lt;- dir(file.path(dirinput,'Images')) # Find all files in our images folder\n\n# Use pattern to take only subject images\nfname &lt;- files[grepl(paste0('^DS.*.jpg$'),files)] \ntbl_files &lt;- as.data.frame(fname) \n\n# First filename part contains subject ID. Create new column with that info. \ntbl_files$subject &lt;- sapply(strsplit(fname,'_'),'[[',1) \n# Preserve the sorting of the field names as in the table\nsorted_fieldnames &lt;- factor(jsonFields$Data.name, levels = jsonFields$Data.name) \n\n# Transform table into a list. Each element is a fieldname with its values\njson_data &lt;- lapply(split(jsonFields$Permissible.values,sorted_fieldnames),as.character)\n\nlibrary(jsonlite)\n\n# Join tables with filenames and subject information by subjID\nmetadat &lt;- dplyr::full_join(x=tbl_files, y=subj_info, by=join_by('subject'=='subjID'),keep=FALSE)  \n\n# write JSON files \nsaveoutput &lt;- 0\nfor (i in 1:nrow(tbl_files)) {\n  \n  # Complete Fields with info From table \n  json_data$IntendedFor = metadat$fname[i]\n  json_data$SubjectID = metadat$subject[i]\n  json_data$Sex = metadat$Sex[i]\n  json_data$BodyWeight_gr = metadat$`Body.weight.(g)`[i]\n  \n  \n  # Convert the list to a JSON string\n  json_string &lt;- toJSON(json_data, pretty = TRUE, auto_unbox = TRUE)\n  \n  # Save the JSON string to a file\n  if (saveoutput == 1) {\n    ouputfilename &lt;- gsub('.jpg','.json',tbl_files$fname[i]) # rename input file\n    write(json_string, file.path(diroutput, ouputfilename))  \n    print(paste0(\"Wrote \", file.path(diroutput, ouputfilename)))\n  }\n  \n  # clean json \n  rm (json_string)\n}\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorials",
      "üè∑**Documentation & Metadata**",
      "Metadata: making JSON files"
    ]
  },
  {
    "objectID": "contents/tutorials/Tutorial_Web.html",
    "href": "contents/tutorials/Tutorial_Web.html",
    "title": "Website Tutorial using R, Quarto and Gitlab Pages",
    "section": "",
    "text": "Sharing documents, code, data and outputs with collaborators or to a broader audience is an essential step towards a good scientific practice. A website that can be managed by researchers themselves seems the ideal platform for efficient sharing. If this depends on IT support for maintenance it will not be practical for routine use, but learning web-development imposes an unnecessary and unacceptable burden to a scientist‚Äôs already heavy workload.\nHere we describe an approach that uses free, open-source tools which are also widely-used for analytic purposes (e.g., data handling, statistics and visualizations). Thus, the requirements for learning web-specific tools is minimal. Importantly, this approach can be integrated in a research group‚Äôs routines to compile dynamic reports with documentation, code, analysis and outputs in a single-document. This makes each step easier to understand, facilitates troubleshooting and improves computational reproducibility see CRS primer",
    "crumbs": [
      "Tutorials",
      "üî≠**Finding, Sharing and Publishing**",
      "Website Tutorial using R, Quarto and Gitlab Pages"
    ]
  },
  {
    "objectID": "contents/tutorials/Tutorial_Web.html#make-a-website-from-scratch-in-5-minutes",
    "href": "contents/tutorials/Tutorial_Web.html#make-a-website-from-scratch-in-5-minutes",
    "title": "Website Tutorial using R, Quarto and Gitlab Pages",
    "section": "1. Make a website from scratch in 5 minutes",
    "text": "1. Make a website from scratch in 5 minutes\nThis 5 minutes video shows how easy it is to create the basic skeleton of the website.\n\nStep 1. Make a new folder for your website\nInside the folder you will have the _quarto.yml file at the top level, then you can organize the quarto markdown files with the content in subfolders if you want.\n\n\nStep 2. Create a _quarto.yml file with some settings\nThey are given in plain text. Indentation counts. There are many examples online which would require minimal adjustments. A very simple example:\nproject:\n    type: website\n    \nwebsite:\n    navbar:\n        title: Home\n        \nformat: \n    html:\n        author: Center for Reproducible Science\n‚Äúnavbar‚Äù indicates a navigation bar on top of the website, but you can also define a ‚Äúsidebar‚Äù. In there you can refer to the different pages that will make up your site. In this example we just make an skeleton with the home page.\n\n\nStep 3. Create a quarto file and open it in R studio\nWe recommend creating an R project file in Rstudio to point at your web‚Äôs folder and open your quarto files with that project open in Rstudio to avoid having future problems finding the path to your files.\nYou can write plain text with markdown syntax on it and use a yml header delimited by --- symbols to add metadata or settings\n\n\nStep 4. Click ‚Äòrender‚Äô or type quarto::quarto_render() in Rstudio\nThat‚Äôs it. A new subfolder named _site will be created with a file index.html which is your website",
    "crumbs": [
      "Tutorials",
      "üî≠**Finding, Sharing and Publishing**",
      "Website Tutorial using R, Quarto and Gitlab Pages"
    ]
  },
  {
    "objectID": "contents/tutorials/Tutorial_Web.html#add-pages-to-your-website",
    "href": "contents/tutorials/Tutorial_Web.html#add-pages-to-your-website",
    "title": "Website Tutorial using R, Quarto and Gitlab Pages",
    "section": "2. Add pages to your website",
    "text": "2. Add pages to your website\nNow we can just populate the pages by:\n\nAdding .qmd files with content. A recommended organization is a page per folder. If a page will contain many subpages, you can set up a main file in that folder (e.g., index.qmd) with a yml header (delimited by ---) using the listing option. This will automatically include all .qmd files without having the need to specifying the _quarto.yml file.\nAdapting the _quarto.yml file to indicate which pages and where you want to show them (e.g., in a navigation bar on top, right or left or in a sidebar)\nClick ‚Äòrender‚Äô or type quarto::quarto_render() in Rstudio\n\nAn example of a folder structure of the website before rendering:\nwebsite\n‚îÇ\n‚îú‚îÄ‚îÄ index.qmd               # (REQUIRED) Contents of home page \n‚îú‚îÄ‚îÄ _quarto.yml             # (REQUIRED) Quarto project configurations \n‚îÇ\n‚îú‚îÄ‚îÄ Project.Rproj           # Recommended when working with R studio \n‚îÇ\n‚îî‚îÄ‚îÄ contents                # (suggested name) Contents of each page\n   ‚îú‚îÄ‚îÄ Page1                # Each page has a folder  \n   |   ‚îî‚îÄ‚îÄ  index.qmd       # A page can be just one qmd\n   ‚îî‚îÄ‚îÄ Page2                 \n       ‚îú‚îÄ‚îÄ  index.qmd       # We can set a page to list all other .qmds in folder     \n       ‚îî‚îÄ‚îÄ  section1.qmd      \nThe following 5.5 minutes video shows a quick example. Read the subtitles for details.",
    "crumbs": [
      "Tutorials",
      "üî≠**Finding, Sharing and Publishing**",
      "Website Tutorial using R, Quarto and Gitlab Pages"
    ]
  },
  {
    "objectID": "contents/tutorials/Tutorial_Web.html#host-it-for-free-using-gitlab-pages",
    "href": "contents/tutorials/Tutorial_Web.html#host-it-for-free-using-gitlab-pages",
    "title": "Website Tutorial using R, Quarto and Gitlab Pages",
    "section": "3. Host it for free using Gitlab pages",
    "text": "3. Host it for free using Gitlab pages\n(‚Ä¶) First activate gitlab pages, then move the content to ‚Äòpublic‚Äô folder (‚Ä¶)",
    "crumbs": [
      "Tutorials",
      "üî≠**Finding, Sharing and Publishing**",
      "Website Tutorial using R, Quarto and Gitlab Pages"
    ]
  }
]